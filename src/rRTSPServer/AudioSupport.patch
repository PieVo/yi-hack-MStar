diff -uar -X exception live/liveMedia/H264or5VideoStreamFramer.cpp live_new/liveMedia/H264or5VideoStreamFramer.cpp
--- live/liveMedia/H264or5VideoStreamFramer.cpp	2020-05-01 19:14:12.648014433 +0000
+++ live_new/liveMedia/H264or5VideoStreamFramer.cpp	2020-05-01 18:57:28.768767197 +0000
@@ -1186,8 +1186,13 @@
       nextPT = usingSource()->fPresentationTime;
       double nextFraction = nextPT.tv_usec/1000000.0 + 1/usingSource()->fFrameRate;
       unsigned nextSecsIncrement = (long)nextFraction;
+#if 0
       nextPT.tv_sec += (long)nextSecsIncrement;
       nextPT.tv_usec = (long)((nextFraction - nextSecsIncrement)*1000000);
+#else
+      // Use system clock to set presentation time
+      gettimeofday(&nextPT, NULL);
+#endif
     }
     setParseState();
 
diff -uar -X exception live/liveMedia/WAVAudioFileSource.cpp live_new/liveMedia/WAVAudioFileSource.cpp
--- live/liveMedia/WAVAudioFileSource.cpp	2020-02-11 21:42:45.000000000 +0000
+++ live_new/liveMedia/WAVAudioFileSource.cpp	2020-05-01 18:54:16.740468541 +0000
@@ -115,7 +115,7 @@
   // http://www.ringthis.com/dev/wave_format.htm
   // http://www.lightlink.com/tjweber/StripWav/Canon.html
   // http://www.onicos.com/staff/iz/formats/wav.html
-
+#if 0
   Boolean success = False; // until we learn otherwise
   do {
     // RIFF Chunk:
@@ -204,6 +204,13 @@
     fBitsPerSample = 0;
     return;
   }
+#else
+  fWAVHeaderSize = 0;
+  fBitsPerSample = 16;
+  fSamplingFrequency = 16000;
+  fNumChannels = 1;
+  fAudioFormat = (unsigned char)WA_PCM;
+#endif
 
   fPlayTimePerSample = 1e6/(double)fSamplingFrequency;
 
@@ -316,7 +323,7 @@
       break; // from the loop (normal case)
     }
   }
-
+#if 0
   // Set the 'presentation time' and 'duration' of this frame:
   if (fPresentationTime.tv_sec == 0 && fPresentationTime.tv_usec == 0) {
     // This is the first frame, so use the current time:
@@ -327,6 +334,10 @@
     fPresentationTime.tv_sec += uSeconds/1000000;
     fPresentationTime.tv_usec = uSeconds%1000000;
   }
+#else
+  // Use system clock to set presentation time
+  gettimeofday(&fPresentationTime, NULL);
+#endif
 
   // Remember the play time of this data:
   fDurationInMicroseconds = fLastPlayTime
diff -uar -X exception live/rRTSPServer.cpp live_new/rRTSPServer.cpp
--- live/rRTSPServer.cpp	2020-05-01 19:14:12.652014418 +0000
+++ live_new/rRTSPServer.cpp	2020-05-01 18:51:51.974002312 +0000
@@ -103,13 +103,17 @@
   {
     char const* streamName = "ch0_0.h264";
     char const* inputFileName = "stdin";
-
+    Boolean convertToULaw = True;
+    char const* inputAudioFileName = "/tmp/audio_fifo";
+ 
     // First, make sure that the RTPSinks' buffers will be large enough to handle the huge size of DV frames (as big as 288000).
     OutPacketBuffer::maxSize = 300000;
 
     ServerMediaSession* sms_high
       = ServerMediaSession::createNew(*env, streamName, streamName,
 				      descriptionString);
+    sms_high->addSubsession(WAVAudioFileServerMediaSubsession
+                       ::createNew(*env, inputAudioFileName, reuseFirstSource, convertToULaw));
     sms_high->addSubsession(H264VideoFileServerMediaSubsession
 		       ::createNew(*env, inputFileName, reuseFirstSource));
     rtspServer->addServerMediaSession(sms_high);
@@ -122,13 +126,17 @@
   {
     char const* streamName = "ch0_1.h264";
     char const* inputFileName = "stdin";
-
+    Boolean convertToULaw = True;
+    char const* inputAudioFileName = "/tmp/audio_fifo";
+ 
     // First, make sure that the RTPSinks' buffers will be large enough to handle the huge size of DV frames (as big as 288000).
     OutPacketBuffer::maxSize = 300000;
 
     ServerMediaSession* sms_low
       = ServerMediaSession::createNew(*env, streamName, streamName,
 				      descriptionString);
+    sms_low->addSubsession(WAVAudioFileServerMediaSubsession
+                       ::createNew(*env, inputAudioFileName, reuseFirstSource, convertToULaw));
     sms_low->addSubsession(H264VideoFileServerMediaSubsession
 		       ::createNew(*env, inputFileName, reuseFirstSource));
     rtspServer->addServerMediaSession(sms_low);
